
services: 
  frontend:
    build: 
      context: ./frontend
      dockerfile: Dockerfile.dev
    ports:
      - "8080:8080"
    depends_on:
      - backend
    volumes:
      - ./frontend:/app 
      - /app/node_modules
    init: true
  
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    depends_on:
      - redis
    volumes:
      - ./uploads:/app/uploads
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - CUDA_VISIBLE_DEVICES=0
    init: true
    runtime: nvidia
  
  worker:
    build: ./celery_worker
    volumes:
      - ./celery_worker:/tasks
    depends_on:
      - redis
      - backend
      - ollama
    environment:
      - OLLAMA_HOST=http://ollama:11434
    init: true
  
  redis:
    image: redis:7
    ports:
      - "6379:6379"
  
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_METAL=1
      - OLLAMA_CONTEXT_LENGTH=32768
    volumes:
      - ollama_data:/root/.ollama
    deploy: {} 
    runtime: nvidia
    init: true

  flower:
    image: mher/flower
    ports:
      - "5555:5555"
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
    depends_on:
      - redis
    init: true

volumes:
  ollama_data: